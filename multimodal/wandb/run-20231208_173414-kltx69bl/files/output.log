/Users/silviaromanato/.conda/envs/lastenv/lib/python3.8/site-packages/transformers/training_args.py:1843: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required.
  warnings.warn(
LOADING DATA (vision: vit)
Loaded image data:	Train: 520	Validation: 62	Test: 74 samples.
Loaded tabular data: 	Train: 260	Validation: 31	Test: 37 samples.
Created datasets:	Train: 260	Validation: 31	Test: 37 samples.
Moving model to device: cpu
Model initialization
	Vision encoder: vit
Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-large-patch32-384 and are newly initialized because the shapes did not match:
- vit.embeddings.position_embeddings: found shape torch.Size([1, 145, 1024]) in the checkpoint and torch.Size([1, 6085, 1024]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
	Tabular encoder with parameters: {'dim_input': 87, 'hidden_dims': [256, 512], 'dropout_prob': 0.0, 'batch_norm': True}
W&B initialization: run Tabular-vit-256-512-p0.0
Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-large-patch32-384 and are newly initialized because the shapes did not match:
- vit.embeddings.position_embeddings: found shape torch.Size([1, 145, 1024]) in the checkpoint and torch.Size([1, 6085, 1024]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.